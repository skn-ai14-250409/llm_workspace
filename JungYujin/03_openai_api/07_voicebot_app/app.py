import streamlit as st
from audiorecorder import audiorecorder
from openai_service import stt, ask_gpt, tts

# from dotenv import load_dotenv
# from openai import OpenAI
# import os
# import base64
#
# load_dotenv() # .env ë‚´ìš©ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
#
# client = OpenAI() # api_keyëŠ” í™˜ê²½ë³€ìˆ˜ì— ìˆìœ¼ë¯€ë¡œ ìƒëµê°€ëŠ¥
#
#
#
#
# def stt(audio):
#     # íŒŒì¼ë¡œ ë³€í™˜
#     filename = 'prompt.mp3'
#     audio.export(filename, format='mp3')
#
#     # whisper-1 ëª¨ë¸ë¡œ stt
#     with open(filename, 'rb') as f:
#         transcription = client.audio.transcriptions.create(
#             model='whisper-1',
#             file=f
#         )
#     # ì„ì‹œìŒì›íŒŒì¼ ì‚­ì œ
#     os.remove(filename)
#     return transcription.text
#
# def ask_gpt(messages, model):
#     response = client.chat.completions.create(
#         model=model,
#         messages=messages,
#         temperature=1,
#         top_p=1,
#         max_tokens=4096
#     )
#     return response.choices[0].message.content
#
# def tts(response):
#     filename='voice.mp3'
#     with client.audio.speech.with_streaming_response.create(
#         model = 'tts-1',
#         voice = 'alloy',
#         input=response
#
#     ) as stream:
#         stream.stream_to_file(filename)
#     # ìŒì›ì„ base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”© ì²˜ë¦¬
#     with open(filename, 'rb') as f:
#         data = f.read()
#         base64_encoded=base64.b64encode(data).decode()
#     # ìŒì›íŒŒì¼ ì‚­ì œ
#     #os.remove(filename)
#     return base64_encoded


def main():
    st.set_page_config(
        page_title='ğŸ˜Voice ChatbotğŸ˜',
        page_icon="ğŸ¤",
        layout='wide'
    )
    st.header('ğŸ¤Voice ChatbotğŸ¤')
    st.markdown('---')

    with st.expander('Voice Chatbot í”„ë¡œê·¸ë¨ ì²˜ë¦¬ì ˆì°¨', expanded=False):
        st.write(
            """
            1. ë…¹ìŒí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ë…¹ìŒí•©ë‹ˆë‹¤.
            2. ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ Whisperëª¨ë¸ì„ ì´ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
            3. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¡œ LLMì— ì§ˆì˜í›„ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
            4. LLMì˜ ì‘ë‹µì„ ë‹¤ì‹œ TTSëª¨ë¸ì„ ì‚¬ìš©í•´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©ìì—ê²Œ ë“¤ë ¤ì¤ë‹ˆë‹¤.
            5. ëª¨ë“  ì§ˆë¬¸/ë‹µë³€ì€ ì±„íŒ…í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.
            """
        )
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [
            {'role':'system', 'content':'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.'}
        ]
    if 'check_reset' not in st.session_state:
        st.session_state['check_reset'] = False

    with st.sidebar:
        model = st.radio(label='GPT ëª¨ë¸', options=['gpt-4.1', 'gpt-4o', 'gpt-4o-mini'], index=2)
        print(f'model={model}')

        if st.button(label='ì´ˆê¸°í™”'):
            st.session_state['check_reset'] = True
            st.session_state['messages'] = [
                {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.'}
            ]

    col1, col2 = st.columns(2)
    with col1:
        st.subheader('ë…¹ìŒí•˜ê¸°')
        audio = audiorecorder()
        if (audio.duration_seconds>0) and (not st.session_state['check_reset']):
            # ìŒì› ì¬ìƒ
            st.audio(audio.export().read())
            #st.session_state['check_reset'] = True

            # stt ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            prompt = stt(audio)
            print(f'prompt={prompt}')

            # chat completion í˜¸ì¶œ
            # - messagesì— ì¶”ê°€
            st.session_state['messages'].append({'role':'user', 'content':prompt})
            # - llm ìš”ì²­
            response = ask_gpt(st.session_state['messages'], model)
            st.session_state['messages'].append({'role': 'assistant', 'content': response})
            print(f'response={response}')


            # llm ì‘ë‹µì„ tts ëª¨ë¸ì„ í†µí•´ ìŒì›íŒŒì¼ë¡œ ë³€í™˜/ì¬ìƒ
            base64_encoded = tts(response)
            #print(base64_encoded)
            st.html(f'''
            <audio>
            #<audio autoplay='true'>
                <source src='data:audio/mp3;base64,{base64_encoded}' type='audio/mp3'/>
            </audio>
            ''')



        #print(audio.duration_seconds)
    with col2:
        st.subheader('ì§ˆë¬¸/ë‹µë³€')
        if (audio.duration_seconds>0) and (not st.session_state['check_reset']):
            for message in st.session_state['messages']:
                role = message['role'] # system/user/assistant
                content = message['content']

                if role == 'system':
                    continue
                # elif role == 'user':
                #     st.session_state['messages'].append({'role': 'assistant', 'content': response})

                #else:

                with st.chat_message(role):
                    st.markdown(content)

        else:
            st.session_state['check_reset'] =False #ì´ˆê¸°í™”ìƒíƒœ ê°’ì€ ì›ë³µ



if __name__ == '__main__':
    main()